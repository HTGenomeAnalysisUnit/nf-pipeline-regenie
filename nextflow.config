cleanup = true

manifest {
    name                                  = 'nf-highspeed-gwas'
    version                               = 'v1.7'
    description                           = 'Regenie GWAS at high speed'
    author                                = 'Edoardo Giacopuzzi'
    homePage                              = 'https://gitlab.fht.org/genome-analysis-unit/nf-pipeline-regenie'
    mainScript                            = 'main.nf'
    nextflowVersion                       = '!>=22.10'
}

singularity {
    cacheDir = '/project/alfredo/singularity'
}

// Global default params, used in configs
params {
    //this is set to true eventually from command line 
    //when you want to run pheno chunks using a master table
    with_master                   = false 
    
    //=== SETTINGS FOR MASTER TABLE MODE ===
    master_outdir                 = null
    master_log_dir                = null
    shared_config_file            = null
    pheno_chunk_size              = null
    missing_tolerance             = null
    max_gwas_submit               = 5
    gwas_submit_profile           = 'slurm'
    nextflow_module               = 'nextflow/22.10.6' //this needs to be the same module used for the master

    //=== GENERAL SETTINGS ===
    project                               = null
    project_date                          = "`date`"
    outdir                                = null
    chromosomes                           = '1-22' //chromosomes to be analyzed. Accepts comma separated list and intervals

    //=== INPUT FILES ===
    //Genetic data 
    genotypes_array                       = null //genotypes data for step 1. Can be bgen, pgen, bed or vcf.gz
    genotypes_imputed                     = null //genotype data for gwas analysis. Can be bgen, pgen, bed or vcf.gz
    genotypes_rarevar                     = null //genotype data for rare variants analysis. Can be bgen, pgen, plink bed or vcf.gz
    genotypes_build                       = null //genome build
    genotypes_imputed_format              = null //input data format for gwas. Can be bgen, pgen, bed or vcf
    genotypes_rarevar_format              = null //input data format for rare variants. Can be bgen, pgen, bed or vcf
    imputed_sample_file                   = 'NO_SAMPLE_FILE' //Provide a specific sample file to use with gwas bgen input
    rarevar_sample_file                   = 'NO_SAMPLE_FILE' //Provide a specific sample file to use with rare variants bgen input
    ld_panel                              = 'NO_LD_FILE' //A pattern pointing to a subset of genotypes to be used for LD computation. Optional, but highly reccomended for large datasets

    //Phenotypes
    phenotypes_filename                   = null //table of phenos - required
    phenotypes_columns                    = null //comma separated list of col names in pheno file to be analyzed
    phenotypes_binary_trait               = null //true for binary
    
    //Covariates
    covariates_filename                   = 'NO_COV_FILE'
    covariates_columns                    = ''
    covariates_cat_columns                = ''
    maxCatLevels                          = 10 //maximum number of allowed levels for categorical covars

    //Rare variants accessory files (mandatory when running rare var analysis)
    rarevar_set_list_file                 = null //set list file as defined in regenie docs
    rarevar_anno_file                     = null //set list file as defined in regenie docs
    rarevar_mask_file                     = null //set list file as defined in regenie docs

    //Optional inputs
    genes_bed                             = false //an optional .bed file specifying genes intervals used for results annotation
    genes_ranges                          = false //an optional .interval file specifying genes intervals used for results annotation

    //=== STEP1 PRE-PROCESSING SETTINGS ===
    //snp pruning process 
    prune_enabled                         = false
    prune_maf                             = 0.01
    prune_window_kbsize                   = 1000
    prune_step_size                       = 100
    prune_r2_threshold                    = 0.9

    //filtering process
    qc_maf                                = '0.01'
    qc_mac                                = '100'
    qc_geno                               = '0.05'
    qc_hwe                                = '1e-15'
    qc_mind                               = '0.1'

    //=== REGENIE STEP1 SETTINGS ===
    regenie_bsize_step1                   = 1000
    regenie_premade_predictions           = false //or pattern to regenie step1 files
    save_step1_predictions                = true
    regenie_force_step1                   = false
    regenie_ref_first_step1               = false
    step1_use_loocv                       = false
    step1_niter                           = 30
    step1_n_chunks                        = 100 // n of chunks when performing step1 L0 regression
    
    //=== REGENIE STEP2 SETTINGS ===
    //General settings
    phenotypes_delete_missings            = false //remove samples with missing data at any of the phenotypes
    regenie_bsize_step2                   = 400
    regenie_ref_first_step2               = true
    regenie_skip_predictions              = false //skip reading the step1 predictions (corresponds to simple linear/logistic regression)
    regenie_range                         = '' // when splitting is not active you can use this to specify a genomic range for step2 analysis
    save_chunks_file                      = true
    save_step2_logs                       = true
    save_snplist                          = true
    save_bgen_index                       = true
    save_bgen_sample                      = true    
    save_pgen                             = true

    //VCF to PGEN conversion settings
    gwas_read_dosage_from                 = 'DS' //DS (usually for VCF from imputateion) or GP (usually VCF from sequencing)
    rarevar_read_dosage_from              = 'GP' //DS (usually for VCF from imputateion) or GP (usually VCF from sequencing)
    import_dosage_certainty               = 0.7 //when using GP, the certainty threshold to import dosages. If none of the probabilities is above this, the genotype is set to missing
    vcf_fixed_fid                         = null //when null vcf is converted to pgen using --double-id, otherwise fid is fixed to this value

    //gwas specific settings
    step2_gwas_split                      = true //when true activate split of step2 by variant chunks
    step2_gwas_chunk_size                 = 100000 //n variants per chunk when running gwas in split mode
    regenie_gwas_test                     = 'additive' //additive, dominant, recessive
    regenie_min_imputation_score          = '0.00'
    regenie_gwas_min_mac                  = '50' // min MAC for variants to be included in step2 for gwas 
    regenie_firth                         = true
    regenie_firth_approx                  = true

    //rarevar specific settings
    step2_rarevar_split                   = true //when true activate split of step2 by gene chunks
    step2_rarevar_chunk_size              = 200 //n genes per chunk when running rare variant test in split mode
    regenie_rarevar_min_mac               = '1' // min MAC for variants to be included in step2 for rare vars
    rarevars_aaf_bins                     = '0.01,0.05' //comma-separated list of AAF upper bounds to use when building masks for burden test
    rarevars_vc_test                      = 'skat,skato,acatv,acato' //comma-separated list of SKAT/ACAT-type tests to run
    rarevars_vc_maxAAF                    = '0.05' //AAF upper bound to use for SKAT/ACAT-type tests
    regenie_build_mask                    = 'max' //build mask for rare variant test. Can be max, sum, or a comphet
    rarevars_write_mask_snplist           = false //when true write list of variants that went into each mask to file

    //=== GWAS RESULTS ANNOTATION AND CLUMPING ===
    annotation_min_log10p                 = 8 //results with -log10(p) above this will be reported as top hits with annotated genes
    annotation_interval_kb                = 25
    clumping                              = true
    clump_p1                              = 5e-8
    clump_p2                              = 1e-4
    clump_kb                              = 250
    
    //=== RARE VARIANTS RESULTS ANNOTATION ===
    rarevar_tophits_min_value             = 1.3 //results with -log10(stat_value) above this will be reported as top hits and annotated in plots
    rarevar_stat_test                     = "BONF_bygroup" //Stat value to filter on. Possible values: "pvalue", "FDR_bygroup", "FDR_alltests", "BONF_bygroup", "BONF_alltests"

    //=== REPORT SETTINGS ===
    make_report                           = true //it can be useful to disable when analyzing many phenotypes
    plot_ylimit                           = 0
    manhattan_annotation_enabled          = true
}

//PIPELINE TRACE FILES
report_file = "${launchDir}/gwas-pipeline_report.html"
timeline_file = "${launchDir}/gwas-pipeline_timeline.html"

report {
    enabled = true
    file = "${report_file}"
}

timeline {
    enabled = true
    file = "${timeline_file}"
}

// Load base.config by default for all pipelines
includeConfig 'conf/base.config'

// Set pipeline container
process.container = 'edg1983/gwas-nf-pipeline:v0.4'

// Computational environments
profiles {
    debug { process.beforeScript          = 'echo $HOSTNAME' }

    test  {
        includeConfig 'conf/test.base.config'
    }

    ht_cluster {
        workDir = "/scratch/$USER/nf-gwas-work"
        process.queue = 'cpuq'
        process.containerOptions = '-B /localscratch'
        executor {
            name = 'slurm'
            queueSize = 200
            pollInterval = '5 sec'
        }
        singularity {
            cacheDir              = '/ssu/gassu/singularity/'
            enabled               = true
            autoMounts            = true
        }
        params {
            max_memory = 512.GB
            max_cpus   = 32
            max_time   = 7.d
        }
        docker.enabled                    = false
    }
}

def check_max(obj, type) {
    if (type == 'memory') {
        try {
            if (obj.compareTo(params.max_memory as nextflow.util.MemoryUnit) == 1)
                return params.max_memory as nextflow.util.MemoryUnit
            else
                return obj
        } catch (all) {
            println "   ### ERROR ###   Max memory '${params.max_memory}' is not valid! Using default value: $obj"
            return obj
        }
    } else if (type == 'time') {
        try {
            if (obj.compareTo(params.max_time as nextflow.util.Duration) == 1)
                return params.max_time as nextflow.util.Duration
            else
                return obj
        } catch (all) {
            println "   ### ERROR ###   Max time '${params.max_time}' is not valid! Using default value: $obj"
            return obj
        }
    } else if (type == 'cpus') {
        try {
            return Math.min( obj, params.max_cpus as int )
        } catch (all) {
            println "   ### ERROR ###   Max cpus '${params.max_cpus}' is not valid! Using default value: $obj"
            return obj
        }
    }
}
